{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "from glob import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path): # 引数にはPDFファイルパスを指定\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    laparams.detect_vertical = True # Trueにすることで綺麗にテキストを抽出できる\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    fstr = ''\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "        str = retstr.getvalue()\n",
    "        fstr += str\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return fstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"documents/JPA-1999069893.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n"
     ]
    }
   ],
   "source": [
    "mecab = MeCab.Tagger (\"-Owakati\")\n",
    "text = convert_pdf_to_txt(path).replace('\\n', '')\n",
    "text = mecab.parse (text)\n",
    "pattern = r\"[0-9A-Za-zぁ-んァ-ヴ一-龠]\"\n",
    "stopwords = re.sub(pattern, '',text)\n",
    "# print(stopwords)\n",
    "\n",
    "def wakati_by_mecab(text):\n",
    "    tagger = MeCab.Tagger('')\n",
    "    tagger.parse('') \n",
    "    node = tagger.parseToNode(text)\n",
    "    word_list = []\n",
    "    while node:\n",
    "        pos = node.feature.split(\",\")[0]\n",
    "        if pos in [\"名詞\"]:   # 対象とする品詞\n",
    "            word = node.surface\n",
    "            word_list.append(word)\n",
    "        node = node.next\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_number(text):\n",
    "    # 連続した数字を0で置換\n",
    "    replaced_text = re.sub(r'\\d+', '', text)\n",
    "    return replaced_text\n",
    "\n",
    "def download_stopwords(path):\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    if os.path.exists(path):\n",
    "        print('File already exists.')\n",
    "    else:\n",
    "        print('Downloading...')\n",
    "        # Download the file from `url` and save it locally under `file_name`:\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "\n",
    "def create_stopwords(path):\n",
    "    stop_words = []\n",
    "    for w in open(path, \"r\"):\n",
    "        w = w.replace('\\n','')\n",
    "        if len(w) > 0:\n",
    "          stop_words.append(w)\n",
    "    return stop_words    \n",
    "\n",
    "file_path = \"/Users/yusuke-n/code/work/read_pdf/stopword.txt\"\n",
    "# text = wakati_by_mecab(text)\n",
    "# text = lower_text(text)\n",
    "# text = normalize_number(text)\n",
    "download_stopwords(file_path)\n",
    "stop_words = create_stopwords(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "comments = [\"あなたは春が好きね\", text]\n",
    "sample_dict = {\"comment\": comments} \n",
    "samples = pd.DataFrame.from_dict(sample_dict)\n",
    "samples[\"target\"] = samples[\"comment\"].apply(wakati_by_mecab).apply(lower_text).apply(normalize_number)\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words=stop_words,token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "feature_vectors = count_vectorizer.fit_transform(samples['target'])\n",
    "vocabulary = count_vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(\n",
    "                      font_path=\"/system/Library/Fonts/ヒラギノ角ゴシック W4.ttc\",\n",
    "                      colormap='copper_r',\n",
    "                      width=800,height=600).generate(samples['target'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x126938940>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"./wordcloud_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
